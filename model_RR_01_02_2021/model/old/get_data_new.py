# -*- coding: utf-8 -*-
"""
Created on Wed Aug 12 15:05:09 2020

@author: de_hauk
"""



'''
Info von MAX:
0,1 unter 3 ist falsch/richtig
unter 4 antwort -> correct as new// correct remembered and vice versa
Index1 = erstes Bild, 
Central Question: Hast du das Geschicht schonmal geshen?// 1==Ja // 0=Nein
Unter 3 kÃ¼rzel 4 Buchstaben
    erst female&male /f,m
    12 Ids per sex = 24 total
    l,f,r = perspektive

Liste == meine Liste Email

differenz zwischen Bild & actual keypress - 750ms presentationszeit ==  RT
dritte zeile IRR
vierte zeile == feedback
RT nicht berechnen weil zu lang -> healthy controls    

performance !!!
'''



import pandas as pd
import glob
import numpy as np
from autoimpute.imputations import MultipleImputer

data_path = r'C:\Users\de_hauk\PowerFolders\apps_tzakiris_rep\data\data_new_12_08_2020\data_raw'


############################################### Data #################################################################################

''' Data Processing in two batches. Second batch containes additional Information in form of an additional row per trial which 
needs to be deleted'''

# ## First Batch
# path_1_batch_raw = data_path + r'\first_batch'
# all_files_1B = glob.glob(path_1_batch_raw + "/*.csv")

# ## Second Batch
# path_2_batch_raw = data_path + r'\second_batch'
all_files = glob.glob(data_path + "/*.csv")

## Merge Batches so that subj 1-5 are first batch and 6-10 are second batch
#all_files = all_files_1B + all_files_2B

## Get raw data i.e. trial list generated by previous optimization run
sample_fullinfo = pd.read_csv(r'C:\Users\de_hauk\PowerFolders\apps_tzakiris_rep\data\data_new_12_08_2020\data_list\stimuli_list.csv')
SAMPLE_fullinfo = sample_fullinfo.drop(columns = ['Unnamed: 0']).copy()

## setup dataframe not containing raw dat
SAMPLE_onlydat = pd.DataFrame()

#raw_dat_unproc = [pd.read_csv(i,sep='\s+', header=None).drop(columns=[0,1,2,5,6,7,8,9]).drop(axis='index', labels = [0]) for i in all_files]
raw_dat_unproc = [i for i in all_files]

pd.read_csv(r'C:\Users\de_hauk\PowerFolders\apps_tzakiris_rep\data\data_new_12_08_2020\data_raw\['sub1_pilotA'].csv')

## For each (subject)-data in directories
for ID in all_files:
    
    curr_ID = ID[-8:-6] ## get unique ID Number/Subject Number from raw dat names
    curr_file = ID ## get current file-path
    
    ## get actual data into dataframe & drop irrelevant clmns
    df_sample_raw = pd.read_csv(curr_file,sep='\s+', header=None).drop(columns=[0,1,2,5,6,7,8,9]).drop(axis='index', labels = [0])
    
    ## select only relevant rows
    ## ACHTUNG: Length of df = batch 1 < batch 2
    ## length use as a seperator to filter irrelevant rows
    
    if len(df_sample_raw[3]) >= 800: # aka. if data from batch 2
        df_sample = df_sample_raw.loc[(df_sample_raw[4] != '2=switched_1=notswitched') & (df_sample_raw[4] != 'actual_key_press_for_RT')]
    else:
        df_sample = df_sample_raw.loc[(df_sample_raw[4] != 'actual_key_press_for_RT')]
        
    ## Initialize protocoll data
    answer_correct = [] #1==yes//0==no 
    faceID_known = [] #1==yes//0==no
    perspective = []
    
    for i,j in zip(df_sample[3], df_sample[4]):

        ### Which stimulus was observed
        if (len(i) == 4) and (i not in ['None','right','left']):
            perspective.append(i)
            
        ### What was the Answer, regardless of correctness??  
        if ('right' in str(i)) and (str(j) == 'left=yes_right=no_None=missed'):
            faceID_known.append(0) # NOT familiar
        elif ('left' in str(i)) and (str(j) == 'left=yes_right=no_None=missed'):
            faceID_known.append(1) # familiar
        elif (str(i) == 'None') and (str(j) == 'left=yes_right=no_None=missed'):
            faceID_known.append(np.nan) # code responding too early and missed responses as np.nan
            
        ### Was the answer correct w.r.t. to the task? // Missing an Answer is also worng
        if (str(i) == '1') and ( 'right' in str(j)):
            answer_correct.append(int(i))
        elif (str(i) == '0') and ( 'wrong' in str(j)):
            answer_correct.append(int(i))
        elif (str(i) == '0') and (str(j) == 'missed'):
            answer_correct.append(int(i))           
      
    
    SAMPLE_fullinfo[str(curr_ID) + 'answer'] = pd.Series(faceID_known)    
    SAMPLE_fullinfo[str(curr_ID) + 'perf'] = pd.Series(answer_correct)
    SAMPLE_fullinfo[str(curr_ID) + 'perspective'] = pd.Series(perspective)
    
    SAMPLE_onlydat[str(curr_ID) + 'answer'] = pd.Series(faceID_known)
    SAMPLE_onlydat[str(curr_ID) + 'perf'] = pd.Series(answer_correct)
    SAMPLE_onlydat[str(curr_ID) + 'perspective'] = pd.Series(perspective)


#################################### Impute missing Data ###############################################################

### determine place and amount of missing value
missing_dat_raw = pd.DataFrame(SAMPLE_fullinfo.isnull().sum(), columns = ['dat'])

### filter out clmns with no missing dat
missing_dat_overview = missing_dat_raw.loc[missing_dat_raw['dat'] > 0].T



#drop irrelevant columns containig weird stim codings
miss_perspect = [i for i in SAMPLE_onlydat if 'perspective' in i ]
miss_dat = SAMPLE_onlydat.drop(labels =miss_perspect, axis = 1 ).copy()

# Impute missing dat with binary logistic regress returning only one DF with imputed values
### Uses = https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
imp = MultipleImputer(n=1,strategy= 'binary logistic',return_list=True, imp_kwgs={"binary logistic": {"max_iter": 10000}} )
impute_res = imp.fit_transform(miss_dat)

# merge imputed DF with relevant Info i.e. generating list etc
DATA_imput = impute_res[0][1]
for i in sample_fullinfo:
    if i not in [i for i in sample_fullinfo if ('answer' in i) or ('perf' in i)]:
        DATA_imput[i] = sample_fullinfo[i]
        
### save to csv
#data_imput.to_csv(r'D:\A_T_Implementation\data_lab_jansen\final_proc_dat_labjansen.csv')
