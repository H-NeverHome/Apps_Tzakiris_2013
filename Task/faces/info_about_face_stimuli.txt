The stimuli were taken from the database of the Social Perception Lab, Princeton (http://tlab.princeton.edu/databases/secretdatabaseportal/). we used the “300 random faces” data set 32, consisting of 300 faces that were randomly generated using the FaceGen software package (version 3.1, https://facegen.com/modeller.htm).
These faces were rated on 9 trait dimensions: attractiveness (n=35), likeability (n=32), trustworthiness (n=29), competence (n=44), extroversion (n=33), dominance (n=23), meanness (n=27), frightening (n=28), and threatening (n=27). We selected 24 faces that were within one standard deviation of the mean on each of the mentioned trait dimensions i.e., the faces were close to the mean on all traits. 
Face stimuli will be presented centrally on a uniform gray background, with 15 ̊ height and 12 ̊ width of the visual angle. As facial identity recognition is typically guided by visual features beyond facial structure, for instance by skin color, we will use color facial stimuli. All faces from the database are shown from the front.
The faces are turned 30° to the left and right, respectively. Participants will be therefore required to recognize faces from novel viewpoints, even if they had not seen that face from this specific viewpoint before.
